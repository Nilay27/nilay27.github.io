
<!DOCTYPE html>
<html>

<style>
* {
    box-sizing: border-box;
}
.row::after {
    content: "";
    clear: both;
    display: table;
}
/* Spacing between rows */
.row + .row { margin-top: 40px; }
/* For mobile phones: */
[class*="col-"] {
    width: 100%;
}
.col-prof-pic { margin:auto; }
/*.col-proj-pic { display:none; }*/
@media only screen and (max-width: 499px) {
    /* For mobile: */
    .container {
        max-width:100%;
        margin:auto;
    }
    /*.col-bio {max-width: 65%;}*/
    /*.col-prof-pic {float:right; margin-left:20px;}*/
    .col-proj-pic {max-width: 50%; float:left; display:inline; padding-right: 15px; }
    .col-proj-desc {max-width: 50%; float:left;}
}
.container {
    width:max-width;
    padding:15px;
}
ul {
    list-style: none;
    margin-left: 0px;
    padding-left: 15px;
    padding-bottom: 0px;
    margin-bottom: 0px;
    columns: 1;
    -webkit-columns: 1;
    -moz-columns: 1;
}
@media only screen and (min-width: 500px) {
    /* For desktop: */
    .container {
        max-width:800px;
        margin:auto;
    }
    .col-bio {max-width: 65%;}
    .col-prof-pic {float:right; margin-left:20px;}
    .col-proj-pic {max-width: 25%; float:left; display:inline; padding-right: 20px; }
    .col-proj-desc {max-width: 75%; float:left;}
}
@media only screen and (min-width: 800px) {
    /* For desktop: */
    ul {
        columns: 2;
        -webkit-columns: 2;
        -moz-columns: 2;
    }
}
a {
    color: #1772d0;
    text-decoration:none;
}
a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
}
body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    line-height:130%;
}
strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
  font-weight: 700;
}
heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
}
papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700;
}
name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 40px;
}
.col-proj-pic img {
    max-width: 100%;
}
.cropcircle {
  border-radius: 100%;
    background: #eee no-repeat center;
    background-size: cover;
}
#profile-img{
    height: 250px;
    width: 250px;
    background-image: url(images/nilay.jpg);
}
span.highlight {
    background-color: #ffffd0;
}
label {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700;
    cursor: pointer;
}
.reveal {
  max-height: 0;
  transition: max-height 0.15s ease-out;
  overflow: hidden;
}
.doc{
  color:red;
}
input:checked + label + .reveal {
  max-height: 500px;
  transition: max-height 0.25s ease-in;
}
input + label:after { content: ""; }
input:checked + label:after { content: ""; }
/*a {
  color: #0254EB;
}
a:visited {
  color: #0254EB;
}*/
a.morelink {
  text-decoration:none;
  outline: none;
}
.morecontent span {
  display: none;
}
</style>



<head>
<meta charset="UTF-8">

<!-- Global site tag (gtag.js) - Google Analytics -->
<!--   <script async
src="https://www.googletagmanager.com/gtag/js?id=UA-111894110-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

        gtag('config', 'UA-111894110-1');
</script> -->

  <title> Kumar Nilay </title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="UCSD.png" type="image/x-icon">
  <link href="https://fonts.googleapis.com/css?family=Lato:300,400,400i,700" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
</head>

<body>
<div class="container">

	<hr /> <br />
  <div class="row">
    <div id="profile-img" class="col-prof-pic cropcircle">
    </div>
    <div class="col-bio">
      <p align="center">
		  <name> Kumar Nilay </name> <br />
		  kumarnilay27@gmail.com

	  </p>

      <p>I am a final year student at <a target="_blank" href="http://www.iitkgp.ac.in/">IIT Kharagpur</a>
      pursuing Integrated Masters in <a target="_blank" href = "http://www.chemistry.iitkgp.ac.in/">
      Chemistry</a>. I have worked on problems mostly related to Computer Vision &amp; Deep Learning and their application in Robotics and Medicines. <!--I did my Bachelor Thesis on <i>Continual Learning</i> under the guidance of <a target="_blank" href="https://scholar.google.co.in/citations?user=5bXSZPYAAAAJ&hl=en">Prof. Pabitra Mitra</a>, <i>Department of Computer Science, IIT Kharagpur</i>.-->
      </p>
      
      <p>This summer I did a research internship at <a target="_blank" href="https://vectorinstitute.ai/"> Vector Institute for Artificial Intelligence</a> in collaboration with <i>Machine Learning Research Group </i> at the <a target="_blank" href="https://www.uoguelph.ca/">University of Guelph</a>, Canada as a <i>Deep Learning Research Assistant</i> where I worked on Synthesis of Single Domain Antibodies using Generative Networks. Before this, I interned at <a target="_blank" href="http://www.lemnis.tech/">Lemnis Technologies</a> in summer 2018 as a <i>Computer Vision Intern</i> where I worked on real-time Eye Tracking of user wearing a VR Headset, which was demonstrated at <a target="_blank" href="https://s2018.siggraph.org/">SIGGRAPH 2018</a>.
      
      </p>

      <p align=center>
        <a target="_blank" href="mailto:kumarnilay27@gmail.com">Email</a> &nbsp;/&nbsp;
    		<a target="_blank" href="https://drive.google.com/file/d/1Tk4iwE9P9eSuG81Cg_r6E_XlXVJkBQ4D/view?usp=sharing">Resume</a>&nbsp;/&nbsp;
    		<a target="_blank" href="http://www.github.com/Nilay27">GitHub</a> &nbsp;/&nbsp;
    		<a target="_blank" href="https://www.linkedin.com/in/kumarnilay27/">Linkedin</a>

	  </p>
    </div>

</div><br /> <hr /><br /><br />


  <div class="row">
	  <heading>Internships</heading>
  </div>

  <div class="row">
  <div class="col-proj-pic"><img style="width:100%; height: 150px", src='images/Vector.jpg'></div>
  <div class="col-proj-desc">
	<a target="_blank" href="https://vectorinstitute.ai/">
	  <papertitle>Vector Institute</papertitle>
	</a><br>
	<strong>Deep Learning Research Intern</strong><br>
	<em>Toronto, Canada </em > &nbsp;&bull; May - July 2019
	<p><div class="more">
    The objective was to develop novel molecules using robust generative networks. I worked on modifying existing models and designing new models to generate new molecules, specifically <b>Single Domain Antibodies </b> and predict their properties by jointly training a Semi-Supervised Variational Autoencoders along with a deep MLP network. Also, I benchmarked the trained network on a supercluster by parallelly running multiple experiments on Salmonella Dataset.
  </div></p>
  </div>
</div>

	<div class="row">
    <div class="col-proj-pic"><img style="width:100%; height: 150px",  src='images/Lemnis.jpeg'></div>
    <div class="col-proj-desc">
      <a target="_blank" href="http://www.lemnis.tech/">
        <papertitle>Lemnis Technologies</papertitle>
      </a><br>
      <strong>Computer Vision Intern</strong><br>
      <em>Singapore </em > &nbsp;&bull; May - July 2018 &nbsp; <a target="_blank" class="doc" href="https://www.youtube.com/watch?v=n_q-VK-WbIg">&bull; Demo Link</a><br>
      <p><div class="more">
        At Lemnis, I worked on <i>Pupil Tracking</i> and <i>Glints Based Detection of Eyes</i> using a gaze detection algorithm for a user wearing a VR headset. I incorporated varying focus of the human eye by working on a novel varifocal algorithm which enabled the eye-tracking in a VR headset. During my internship, I also worked towards resolving the FPS Barrier of OpenCV capture (i.e. restricted to 30 FPS) by using Direct Show method and even parallelizing capture and output in multiple threads, which improved the FPS by <b>400%</b> on supported cameras. Moreover, the designed algorithms resulted in <b>800%</b> reduction in the run time of the varifocal algorithm demonstration of the at SIGGRAPH 2018.
      </div></p>
    </div>
  </div>

  <div class="row">
    <div class="col-proj-pic"><img style="width:100%; height: 150px", src='images/223d.gif'></div>
    <div class="col-proj-desc">
      <a>
        <papertitle>223-D</papertitle>
      </a><br>
      <strong>Deep Learning Intern</strong><br>
      <em>California, San Francisco &bull; Remote </em > &nbsp;&bull; March - August 2018 &nbsp;<br>
      <p><div class="more">
        During my internship at 223-D, I worked on various algorithms and applied them to real-world problems. I developed a blend of CEILNet for reflection removal from cars and Densenet for pixel-wise semantic segmentation of objects. Moreover, I performed object detection by using a mix of YOLO and Single Shot Multibox Detector and then extracted the object using Grab Cut algorithm. Thus, improving the image quality using VGG-19 on DPED dataset to generate DSLR like quality and hooked it to a server for real-time demo. Also, I produced a depth map from a single image by implementing FCRN-Depth Prediction algorithm and blurred the image according to depth. 
      </div></p>
    </div>
  </div>

 <!-- <div class="row">
    <heading>Publications</heading>
  </div>

  <div class="row">
    <div class="col-proj-pic"><img src='images/publ.gif'></div>
    <div class="col-proj-desc">
      <a target="_blank" href="https://arxiv.org/pdf/1812.10325.pdf">
		  <papertitle>Cluster Loss for Person Re-Identification</papertitle>
        </a><br>
        <i>Doney Alex, <strong> Kumar Nilay </strong>, Sumandeep Banerjee, Subrat Panda</i><br>
        Published in <a target="_blank" href="https://cvit.iiit.ac.in/icvgip18/">ICVGIP 2018 </a> &nbsp; <a target="_blank" class="doc" href="https://arxiv.org/pdf/1812.10325.pdf">&bull; arXiv Link</a> &nbsp;&nbsp; <a target="_blank" class="doc" href="https://drive.google.com/open?id=1byyC182-pUc3eX-1QolCbmyJrMSQo6eh">&bull; Demo Link</a><br>
      <p><div class="more">
        <i>Abstract : </i>Person re-identification (ReID) is an important problem in computer vision, especially for video surveillance applications. The problem focuses on identifying people across different cameras or across different frames of the same camera. The main challenge lies in identifying the similarity of the same person against large appearance and structure variations, while differentiating between individuals. Recently, deep learning networks with triplet loss have become a common framework for person ReID. However, triplet loss focuses on obtaining correct orders on the training set. We demonstrate that it performs inferior in a clustering task. In this paper, we design a cluster loss, which can lead to the model output with a larger inter-class variation and a smaller intra-class variation compared to the triplet loss. As a result, our model has a better generalization ability and can achieve higher accuracy on the test set especially for a clustering task. We also introduce a batch hard training mechanism for improving the results and faster convergence of training.
      </div></p>
    </div>
  </div> -->

  <div class="row">
    <heading>Research Projects / Competitions </heading>
    <br /><br />
        My research interests broadly include machine learning and deep learning. In particular, I'm interested in research applicable to computer vision, robotics, medicines, and natural language understanding.
  </div>

  <div class="row">
    <div class="col-proj-pic"><img style="widt : 100%; height: 150px"src='images/tctd.gif'></div>
    <div class="col-proj-desc">
      <a target="_blank" href="https://docs.google.com/document/d/1Zzm8E1WA39-_xw-hUD8fPyoJkj-4BViY8yOddyhYR1U/edit?usp=sharing">
		  <papertitle>Automated Fruit Plucking Robot</papertitle>
        </a><br>
        <strong>Inter IIT Tech Meet, 2019</strong> <br>
       <em>IIT Bombay </em > &nbsp;&bull; Sept'18 - December'19 &nbsp; <a target="_blank" class="doc" href="https://drive.google.com/file/d/1vc02s-O9qX_0kbBiPQB52fMs4d9vUz7Z/view?usp=sharing">&bull; Demo Link</a><br>
      <p><div class="more">
          As the <b> Captain</b> of the team and also a member of the vision team, I worked on computer vision algorithms for a robot capable of detecting fruits and navigating through farms to pluck the fruits autonomously. The bot can successfully navigate on a mapped path and detect fruits with the help of a computationally efficient binarized neural network  along with a sliding-windows method, which is implementation on an FPGA board. The custom BNN-network has an accuracy of 95.8% on fruit identification and can run up to 30 FPS on an FPGA board.  The bot uses point clouds and depth data acquired from X-box Kinect to extract the real-world coordinates of the detected fruits in 3D. 
      </div></p>
    </div>
  </div>

  <div class="row">
    <div class="col-proj-pic"><img style="width: 100%; height: 150px"src='images/ATCS.png'></div>
    <div class="col-proj-desc">
      <a target="_blank" href="https://drive.google.com/file/d/1TBJTfL_hFiFe4D2mYdGHOri3v1gJsG7o/view?usp=sharing">
		  <papertitle>Toilet Cleaning Robot</papertitle>
        </a><br>
         <strong> Winner, Inter IIT Tech Meet, 2018 </strong> <br>
       <em>IIT Madras </em > &nbsp;&bull; November'17 - January'18 &nbsp; <a target="_blank" class="doc" href="https://drive.google.com/file/d/1n0AwJNh6518LKu6-mHUV7R0J6uCNeuzc/view?usp=sharing">&bull; Demo of the Competition</a><br>
      <p><div class="more">
        My team won <b>Gold Medal</b> for the Automated Toilet Cleaning Robot Competition among 23 participating IITs all over India.
 I worked on developing algorithms for a robot capable of navigating and identifying toilet seats and stains to clean the entire washroom autonomously. The bot uses Tiny-YOLO for commode detection on Raspberry-Pi using Movidius Neural Compute Stick, which is a Visual Processing Unit. For stain segmentation, I applied otsu binarization along with watershed algorithm, and for seat detection, I trained a HOG+SVM model. 
	 </div></p>
    </div>
  </div>


  <div class="row">
    <div class="col-proj-pic"><img style="height: 150px; width: 100%" src='images/AGV.jpeg'></div>
    <div class="col-proj-desc">
      <a target="_blank" href="https://www.linkedin.com/company/autonomous-ground-vehicle-research-group/">
        <papertitle>Autonomous Ground Vehicle</papertitle>
      </a><br>
      <strong>IIT Kharagpur</strong> &bull; March '16 - December'18 &nbsp; <a target="_blank", class="doc", href="https://youtu.be/UQHZk3ATOG8">&bull; Demo Link</a><br>
      <p>  <div class="more">
        The team secured <b> World Rank 2</b> at 26th International Ground Vehicle Competition (IGVC) among the 43 participating teams worldwide. I worked on the model for detection of cars, identification of traffic lights and recognition of traffic signals. Implemented stereo-vision using PCL library, detected traffic light and traffic sign using faster-RCNN object detection algorithm.
	 </div> </p>
    </div>
  </div>

  <div class="row">
    <div class="col-proj-pic"><img style="height: 150px; width: 100%" src='images/seesaw.gif'></div>
    <div class="col-proj-desc">
      <a target="_blank" href="https://docs.google.com/document/d/1EcnG7FUT1gxefiNUb1PVHSZ5JiUfL4IQNdZE5TxWAn0/edit?usp=sharing">
        <papertitle>SeeSAW.CSV</papertitle>
      </a><br>
      <strong> <a target="_blank", class="doc", href="https://sparkle.kpit.com/"> KPIT Sparkle,2018 </a> </strong> &bull; Top 100 projects nationwide <br>
      <p><div class="more">
        Self-Sustainable Autonomous Water Cleaning Surface Vehicle (SeeSAW.CSV) got selected among <b> top 100 projects</b> from over 2300 projects submitted nationwide. SeeSAW.CSV is an autonomous robot that can detect and collect garbage in a lake, using vision and planning. I worked on the perception and path planning of the robot using Raspberry-Pi and developed a machine learning model for garbage detection. 

	  </div></p>
    </div>
  </div>

  

  <!-- <div class="row">
  <heading>Open-Source</heading>
  </div>

  <div class="row">

    <div class="col-proj-pic"><img src='images/cnn.png'></div>
    <div class="col-proj-desc">
      <a target="_blank" href="https://github.com/zishansami102/CNN-from-Scratch">
        <papertitle>CNN-from-Scratch</papertitle>
      </a><br>
      <strong><i class="fa fa-github"></i> GitHub &nbsp; &nbsp; <i class="fa fa-star"></i> 140+ &nbsp; &nbsp; <i class="fa fa-code-fork" aria-hidden="true"></i> 50+</strong><br>
      <a target="_blank" class="doc" href="https://github.com/zishansami102/CNN-from-Scratch">&bull; Repository </a>&nbsp; &nbsp; <a target="_blank" class="doc" href="https://cnndigits.pythonanywhere.com/  ">&bull; Live Demo </a>
      <p><div class="more">
        A simple CNN implemented in <b>Numpy</b>. It is currently the most popular repository for the
        ground up implementation of CNNs. Demo running on Flask server.
      </div></p>
    </div>
  </div> -->

<div class="row">
    <heading>Training</heading>
</div>
  <div class="row">
  <div class="col-proj-pic"><img style="height: 150px; width: 100%" src="images/IEEE.png"></div>
  <div class="col-proj-desc">
    <a target="_blank" href="https://2018.robotix.in/winter-workshop/">
    <papertitle>IEEE Image Processing Workshop, 2016</papertitle> </a> <br>
    <strong>IIT Kharagpur</strong> &bull; December' 16&nbsp;
    <p><div class="more">
        Successfully completed a 80+ hour IEEE certified workshop on Image Processing and implemented various Image Processing algorithms in OpenCV. Completed the final problem statement to solve the problem of keeping a track of number of goals scored in a Robo-soccer match and the number of people entering a room.

    </div></p>
  </div>
  </div>
  
  <div class="row">
  <heading>Leadership Roles</heading>
  </div>

  <div class="row">
	<div class="col-proj-pic"><img style="height: 90px" src="images/TCTD.jpg"></div>
	<div class="col-proj-desc">
	  

		<a target="_blank" href="http://www.iitb.ac.in/en/event/7th-inter-iit-tech-meet">
		<papertitle>Captain, Inter IIT Tech Meet, 2019</papertitle>
		</a>
		<br><em>TCTD Challange, IIT Kharagpur</em>
    <p>Led a team of 14 members from IIT Kharagpur for the annual Inter IIT Tech Meet, 2018-19.</p>

		<a target="_blank" href="">
		<papertitle>Captain, Hardware Modelling Team, 2018-19</papertitle>
		</a>
		<br><em>Radhakrishnan Hall of Residence, IIT Kharagpur</em>
    <p>Led a team of 40+ members from R.K. Hall of Residence in the Inter Hall Hardware Modelling  2018-19 for the prestigious annual <a target="_blank" href="https://wiki.metakgp.org/w/General_Championship_(Technology)"> Technology General Championship 2018-19.</a></p>

    <a target="_blank" href="">
    <papertitle>Department Representative, Session 2018-19</papertitle>
    </a>
    <br><em>Department Of Chemistry, IIT Kharagpur</em>
    <p>Elected as the Department Representative for all the  Undergraduate students of the Department of Chemistry. Member of the UG council for the session 2018-19, under the <a target="_blank" href="https://www.linkedin.com/in/sudhirkumarbarai/?originalSubdomain=in"> Dean of Undergraduate Studies, IIT Kharagpur</a></p>

		
	</div>
  </div>

 
  <br /><br /><hr />
  <div class="row">
  <p align="right">
    <font size="2">
		<center>
	  © 2019> Kumar Nilay . All rights reserved. <br />
      Website cloned from <a target="_blank" href="http://people.eecs.berkeley.edu/~barron/">here.</a>

  		</center>
    </font>
  </p>
  </div>
   <hr />

</div>
</body>
</html>

<script type="text/javascript">
  $(document).ready(function() {
  var showChar = 270;
  var ellipsestext = " ... ";
  var moretext = "more";
  var lesstext = "less";
  $('.more').each(function() {
    var content = $(this).html();

    if(content.length > showChar) {

      var c = content.substr(0, showChar);
      var h = content.substr(showChar, content.length - showChar);

      var html = c + '<span class="moreelipses">'+ellipsestext+'</span><span class="morecontent"><span>' + h + '</span>&nbsp;&nbsp;<a href="" class="morelink">'+moretext+'</a></span>';

      $(this).html(html);
    }

  });

  $(".morelink").click(function(){
    if($(this).hasClass("less")) {
      $(this).removeClass("less");
      $(this).html(moretext);
    } else {
      $(this).addClass("less");
      $(this).html(lesstext);
    }
    $(this).parent().prev().toggle();
    $(this).prev().toggle();
    return false;
  });
});
</script>